{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a9b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax import random, jit\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0554b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "X, y = noisy_moons\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b63995d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n01(key,N):\n",
    "    D = 2\n",
    "    return random.normal(key, (N, D))\n",
    "\n",
    "def log_prob_n01(x):\n",
    "    return jnp.sum(-jnp.square(x)/2 - jnp.log(jnp.sqrt(2*jnp.pi)),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ff536a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvp_forward(net_params, shift_and_log_scale_fn, x, flip=False):\n",
    "    \n",
    "    d = x.shape[-1]//2\n",
    "    x1, x2 = x[:, :d], x[:, d:]\n",
    "    if flip:\n",
    "        x2, x1 = x1, x2\n",
    "        \n",
    "    shift, log_scale = shift_and_log_scale_fn(net_params, x1)\n",
    "    y2 = x2*jnp.exp(log_scale) + shift\n",
    "    \n",
    "    if flip:\n",
    "        x1, y2 = y2, x1\n",
    "    y = jnp.concatenate([x1, y2], axis=-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71463600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvp_inverse(net_params, shift_and_log_scale_fn, y, flip=False):\n",
    "    d = y.shape[-1]//2\n",
    "    y1, y2 = y[:, :d], y[:, d:]\n",
    "    \n",
    "    if flip:\n",
    "        y1, y2 = y2, y1\n",
    "    \n",
    "    shift, log_scale = shift_and_log_scale_fn(net_params, y1)\n",
    "    x2 = (y2-shift)*jnp.exp(-log_scale)\n",
    "    \n",
    "    if flip:\n",
    "        y1, x2 = x2, y1\n",
    "    \n",
    "    x = jnp.concatenate([y1, x2], axis=-1)\n",
    "    return x, log_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e010b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_nvp(net_params, shift_log_scale_fn, base_sample_fn, N, flip=False):\n",
    "    x = base_sample_fn(N)\n",
    "    return nvp_forward(net_params, shift_log_scale_fn, x, flip=flip)\n",
    "\n",
    "def log_prob_nvp(net_params, shift_log_scale_fn, base_log_prob_fn, y, flip=False):\n",
    "    x, log_scale = nvp_inverse(net_params, shift_log_scale_fn, y, flip=flip)\n",
    "    ildj = -jnp.sum(log_scale, axis=-1)\n",
    "    return base_log_prob_fn(x) + ildj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48680866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import stax # neural network library\n",
    "from jax.experimental.stax import Dense, Relu # neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c2d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nvp(key):\n",
    "    D = 2\n",
    "    net_init, net_apply = stax.serial(\n",
    "        Dense(512), Relu, Dense(512), Relu, Dense(D))\n",
    "    in_shape = (-1, D//2)\n",
    "    out_shape, net_params = net_init(key, in_shape)\n",
    "    \n",
    "    def shift_and_log_scale_fn(net_params, x1):\n",
    "        s = net_apply(net_params, x1)\n",
    "        return np.split(s, 2, axis=1)\n",
    "    \n",
    "    return net_params, shift_and_log_scale_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63bd1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nvp_chain(keys):\n",
    "    flip = False\n",
    "    ps, configs = [], []\n",
    "    for key in keys:\n",
    "        p, f = init_nvp(key)\n",
    "        ps.append(p), configs.append((f, flip))\n",
    "        flip = not flip\n",
    "    return ps, configs\n",
    "\n",
    "def sample_nvp_chain(ps, configs, base_sample_fn, N):\n",
    "    x = base_sample_fn(N)\n",
    "    for p, config in zip(ps, configs):\n",
    "        shift_log_scale_fn, flip = config\n",
    "        x = nvp_forward(p, shift_log_scale_fn, x, flip=flip)\n",
    "    return x\n",
    "\n",
    "def make_log_prob_fn(p, log_prob_fn, config):\n",
    "    shift_log_scale_fn, flip = config\n",
    "    return lambda x: log_prob_nvp(p, shift_log_scale_fn, log_prob_fn, x, flip=flip)\n",
    "\n",
    "def log_prob_nvp_chain(ps, configs, base_log_prob_fn, y):\n",
    "    log_prob_fn = base_log_prob_fn\n",
    "    for p, config in zip(ps, configs):\n",
    "        log_prob_fn = make_log_prob_fn(p, log_prob_fn, config)\n",
    "    return log_prob_fn(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ab5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental import optimizers\n",
    "from jax import jit, grad\n",
    "import numpy as onp\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "*subkeys, key = random.split(key,5)\n",
    "\n",
    "ps, cs = init_nvp_chain(subkeys)\n",
    "\n",
    "\n",
    "def loss(params, batch):\n",
    "    return -jnp.mean(log_prob_nvp_chain(params, cs, log_prob_n01, batch))\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(step_size=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b2c90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def step(i, opt_state, batch):\n",
    "    params = get_params(opt_state)\n",
    "    g = grad(loss)(params, batch)\n",
    "    return opt_update(i, g, opt_state)\n",
    "\n",
    "iters = int(1e4)\n",
    "data_generator = (X[np.random.choice(X.shape[0], 100)] for _ in range(iters))\n",
    "opt_state = opt_init(ps)\n",
    "\n",
    "for i in range(iters):\n",
    "    opt_state = step(i, opt_state, next(data_generator))\n",
    "    \n",
    "ps = get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    " from matplotlib import animation, rc\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "x = sample_n01(1000)\n",
    "values = [x]\n",
    "for p, config in zip(ps, cs):\n",
    "  shift_log_scale_fn, flip = config\n",
    "  x = nvp_forward(p, shift_log_scale_fn, x, flip=flip)\n",
    "  values.append(x)\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "y = values[0]\n",
    "paths = ax.scatter(y[:, 0], y[:, 1], s=10, color='red')\n",
    "\n",
    "def animate(i):\n",
    "  l = i//48\n",
    "  t = (float(i%48))/48\n",
    "  y = (1-t)*values[l] + t*values[l+1]\n",
    "  paths.set_offsets(y)\n",
    "  return (paths,)\n",
    "anim = animation.FuncAnimation(fig, animate, frames=48*len(cs), interval=1, blit=False)\n",
    "anim.save('anim.gif', writer='imagemagick', fps=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
